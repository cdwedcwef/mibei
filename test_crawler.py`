#!/usr/bin/env python3
"""
测试爬虫功能的简单脚本
用于验证爬虫是否能正常工作
"""

import sys
import os

# 添加当前目录到Python路径
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from enhanced_crawler import EnhancedNodeCrawler
    print("✅ 成功导入EnhancedNodeCrawler")
except ImportError as e:
    print(f"❌ 导入失败: {e}")
    sys.exit(1)

def test_crawler():
    """测试爬虫功能"""
    print("🧪 开始测试爬虫功能...")
    
    crawler = EnhancedNodeCrawler()
    
    # 测试获取最新文章链接
    print("\n1. 测试获取最新文章链接...")
    article_url = crawler.get_latest_article_url()
    
    if article_url:
        print(f"✅ 成功获取文章链接: {article_url}")
        
        # 测试提取订阅链接
        print("\n2. 测试提取订阅链接...")
        subscription_url = crawler.extract_subscription_link(article_url)
        
        if subscription_url:
            print(f"✅ 成功提取订阅链接: {subscription_url}")
            
            # 测试下载订阅内容
            print("\n3. 测试下载订阅内容...")
            content = crawler.download_subscription_content(subscription_url)
            
            if content:
                print(f"✅ 成功下载订阅内容，长度: {len(content)} 字符")
                print(f"📝 内容预览（前200字符）: {content[:200]}...")
                
                # 保存测试文件
                with open('test_subscription.txt', 'w', encoding='utf-8') as f:
                    f.write(content)
                print("✅ 测试内容已保存到 test_subscription.txt")
                
                return True
            else:
                print("❌ 下载订阅内容失败")
        else:
            print("❌ 提取订阅链接失败")
    else:
        print("❌ 获取最新文章链接失败")
    
    return False

if __name__ == "__main__":
    print("🚀 节点订阅爬虫测试工具")
    print("=" * 50)
    
    success = test_crawler()
    
    print("\n" + "=" * 50)
    if success:
        print("🎉 所有测试通过！爬虫功能正常")
        print("💡 提示：现在可以部署到GitHub Actions了")
    else:
        print("⚠️ 部分测试失败，请检查：")
        print("   - 网络连接")
        print("   - 目标网站可访问性")
        print("   - 网站结构是否变化")
        print("   - 可能需要更新爬虫脚本")
    
    sys.exit(0 if success else 1)
