# 节点订阅链接自动更新器

这是一个部署在GitHub上的自动化项目，用于每日自动获取最新的节点订阅链接并生成固定链接。

## 🚀 功能特点

- ✅ 自动从指定网站获取最新文章链接
- ✅ 智能提取文章中的订阅链接信息
- ✅ 将订阅内容存储在GitHub仓库中
- ✅ 生成固定的GitHub订阅链接
- ✅ 每日定时执行（早上9点和下午14点）
- ✅ 反爬虫机制处理
- ✅ 自动重试和错误处理
- ✅ 手动触发更新功能

## 📋 部署步骤

### 1. Fork仓库
- 点击GitHub页面右上角的"Fork"按钮
- 将此仓库复制到你的GitHub账户

### 2. 启用GitHub Actions
- 进入你的仓库页面
- 点击"Actions"标签
- 如果提示启用Actions，点击"Enable Actions"

### 3. 获取订阅链接
你的固定订阅链接为：
```
https://raw.githubusercontent.com/你的用户名/仓库名/main/subscription.txt
```

将 `你的用户名` 和 `仓库名` 替换为实际值。

## 🔧 使用方法

### 自动更新
- 项目会自动在每天**早上9:00**和**下午14:00**（北京时间）执行
- 如果早上9:00成功更新，下午14:00将不再执行
- 更新成功后，当天不再重复执行

### 手动更新
1. 进入你的仓库页面
2. 点击"Actions"标签
3. 选择"Update Subscription"工作流
4. 点击"Run workflow"按钮
5. 可选择"强制更新"选项忽略今日已更新检查

## 📁 项目结构

```
├── .github/workflows/
│   └── update-subscription.yml    # GitHub Actions工作流
├── enhanced_crawler.py            # 增强版爬虫脚本
├── crawler.py                     # 基础版爬虫脚本
├── requirements.txt               # Python依赖
├── README.md                      # 项目说明
└── .gitignore                     # Git忽略文件
```

## ⚙️ 技术特性

### 反爬虫处理
- 随机User-Agent轮换
- 请求间隔随机化
- 自动重试机制
- 多种解析策略

### 错误处理
- 网络请求失败自动重试
- 内容格式验证
- 执行状态记录
- 详细的日志输出

## 🔍 工作原理

1. **获取最新文章**：访问目标网站首页，查找最新的文章链接
2. **提取订阅链接**：从文章内容中智能提取订阅链接
3. **下载订阅内容**：下载订阅链接中的节点信息
4. **保存到仓库**：将内容保存到`subscription.txt`文件
5. **自动提交**：通过GitHub Actions自动提交更改

## 📊 状态监控

项目会生成以下状态文件：
- `subscription.txt` - 最新的订阅内容
- `last_updated.txt` - 最后更新时间
- `crawler_status.json` - 爬虫执行状态

## ⚠️ 注意事项

1. 首次部署后需要等待定时任务执行或手动触发
2. 如果网站结构发生变化，可能需要更新爬虫脚本
3. 请遵守目标网站的robots.txt和使用条款
4. 建议定期检查订阅链接是否正常工作

## 🆘 故障排除

### 常见问题

**Q: 订阅链接无法访问**
A: 检查仓库是否公开，链接格式是否正确

**Q: 自动更新失败**
A: 查看GitHub Actions日志，检查网络连接和网站可访问性

**Q: 订阅内容为空**
A: 可能是网站结构变化，需要更新爬虫脚本

### 技术支持
如果遇到问题，请检查：
1. GitHub Actions执行日志
2. 仓库的公开/私有设置
3. 网络连接状态
4. 目标网站是否可访问

---

**最后更新**: 2025-09-30
